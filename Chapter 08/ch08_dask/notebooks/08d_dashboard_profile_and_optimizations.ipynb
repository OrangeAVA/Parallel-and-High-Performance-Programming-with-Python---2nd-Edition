{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122c5c07",
   "metadata": {},
   "source": [
    "# 08d â€” Dashboard, Performance Report & Optimizations\n",
    "\n",
    "Start a Dask `Client`, then explore performance reporting and a few common tuning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, performance_report\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dashboard (if enabled): http://localhost:8787/status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23143a6",
   "metadata": {},
   "source": [
    "## Performance report demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb14caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "N = 2_000_000\n",
    "pdf = pd.DataFrame({\n",
    "    'user_id': np.random.randint(1, 50_000, size=N),\n",
    "    'category': np.random.choice(['Groceries','Electronics','Clothing','Books'], size=N),\n",
    "    'amount': np.random.uniform(1.0, 500.0, size=N),\n",
    "    'timestamp': pd.date_range('2023-01-01', periods=N, freq='s')\n",
    "})\n",
    "ddf = dd.from_pandas(pdf, npartitions=8)\n",
    "\n",
    "with performance_report(filename='dask-performance-report.html'):\n",
    "    summary = ddf['amount'].describe().compute()\n",
    "    cat_sum = ddf.groupby('category')['amount'].sum().compute()\n",
    "\n",
    "summary, cat_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a04123",
   "metadata": {},
   "source": [
    "> A file `dask-performance-report.html` will be saved beside the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bdf14c",
   "metadata": {},
   "source": [
    "## Memory typing optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mb = pdf.memory_usage(deep=True).sum()/1e6\n",
    "print('Original (MB):', round(orig_mb,2))\n",
    "\n",
    "opt = pdf.copy()\n",
    "opt['user_id'] = opt['user_id'].astype('int32')\n",
    "opt['category'] = opt['category'].astype('category')\n",
    "opt['amount'] = opt['amount'].astype('float32')\n",
    "\n",
    "opt_mb = opt.memory_usage(deep=True).sum()/1e6\n",
    "print('Optimized (MB):', round(opt_mb,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09124b21",
   "metadata": {},
   "source": [
    "## `persist()` to cache intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "filt = ddf[ddf['amount']>250]\n",
    "\n",
    "# without persist\n",
    "s = time.time();\n",
    "mean1 = filt['amount'].mean().compute(); count1 = filt['amount'].count().compute();\n",
    "print('No persist secs:', round(time.time()-s,3))\n",
    "\n",
    "# with persist\n",
    "s = time.time();\n",
    "fp = filt.persist()\n",
    "mean2 = fp['amount'].mean().compute(); count2 = fp['amount'].count().compute();\n",
    "print('With persist secs:', round(time.time()-s,3))\n",
    "\n",
    "mean1, count1, mean2, count2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c09e4a",
   "metadata": {},
   "source": [
    "## Chunking / partitions trade-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(df, label):\n",
    "    import time\n",
    "    s=time.time();\n",
    "    v = df['amount'].mean().compute();\n",
    "    print(f'{label}: {round(time.time()-s,3)}s, partitions={df.npartitions}, mean={v:.2f}')\n",
    "\n",
    "small = dd.from_pandas(pdf, npartitions=64)\n",
    "large = dd.from_pandas(pdf, npartitions=1)\n",
    "opt   = dd.from_pandas(pdf, npartitions=8)\n",
    "\n",
    "timing(small, 'Too small chunks')\n",
    "timing(large, 'Too large chunks')\n",
    "timing(opt,   'Optimal-ish chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3589b",
   "metadata": {},
   "source": [
    "## `map_partitions` and Array `rechunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915174ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_squared_column(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    frame = frame.copy()\n",
    "    frame['amount_sq'] = frame['amount'] ** 2\n",
    "    return frame\n",
    "\n",
    "no_opt = ddf.assign(amount_sq = ddf['amount']**2)\n",
    "%time m1 = no_opt['amount_sq'].mean().compute()\n",
    "\n",
    "opt_df = ddf.map_partitions(add_squared_column).persist()\n",
    "%time m2 = opt_df['amount_sq'].mean().compute()\n",
    "\n",
    "m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e6b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "arr = da.random.random((5000,5000), chunks=(100,100))\n",
    "%time s1 = arr.sum().compute()\n",
    "arr2 = arr.rechunk((1000,1000))\n",
    "%time s2 = arr2.sum().compute()\n",
    "float(s1), float(s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
