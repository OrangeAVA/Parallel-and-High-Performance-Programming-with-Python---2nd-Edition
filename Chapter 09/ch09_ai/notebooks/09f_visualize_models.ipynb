{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721398cc",
   "metadata": {},
   "source": [
    "# Visualizing PyTorch models & exporting TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7d91e",
   "metadata": {},
   "source": [
    "Visualize PyTorch models with **torchviz**, **torchsummary**, **torchinfo**, and export TorchScript for **Netron**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e12fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f737ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64*6*6, 600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(600, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchviz\n",
    "from torchviz import make_dot\n",
    "model = FashionCNN()\n",
    "example = torch.randn(1,1,28,28)\n",
    "out = model(example)\n",
    "dot = make_dot(out, params=dict(model.named_parameters()))\n",
    "dot.render('FashionCNN', format='png')\n",
    "print('Saved graph to FashionCNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20dc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchSummary\n",
    "from torchsummary import summary as ts_summary\n",
    "ts_summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e823409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchInfo\n",
    "from torchinfo import summary as info_summary\n",
    "info_summary(model, input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export TorchScript for Netron\n",
    "model.eval()\n",
    "traced = torch.jit.trace(model, example)\n",
    "traced.save(\"FashionCNN.pt\")\n",
    "print(\"Saved TorchScript model: FashionCNN.pt\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
