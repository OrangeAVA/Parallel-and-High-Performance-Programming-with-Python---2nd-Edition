{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pyspark.sql import SparkSession, functions as F\nfrom pyspark import StorageLevel\n\nspark = SparkSession.builder.appName(\"Optimizations\").master(\"local[*]\").getOrCreate()\n\n# RDD path\nrdd = spark.sparkContext.textFile(\"data/transactions.csv\")\nheader = rdd.first()\ndata = (rdd.filter(lambda r: r != header)\n           .map(lambda r: r.split(\",\"))\n           .map(lambda c: (int(c[0]), float(c[1]))))\n\n# Partitioning & Cache\ndata = data.repartition(4)\ndata.cache()\n\n# Broadcast for filtering\nvip_users = [1, 2]\nb_vips = spark.sparkContext.broadcast(vip_users)\nvip_data = data.filter(lambda x: x[0] in b_vips.value)\n\n# combineByKey to sum and avg per user\nuser_totals = (vip_data.combineByKey(\n                    lambda v: (v,1),\n                    lambda acc, v: (acc[0]+v, acc[1]+1),\n                    lambda a,b: (a[0]+b[0], a[1]+b[1])\n                )\n                .mapValues(lambda x:(x[0], x[0]/x[1])))\n\nprint(\"RDD results (VIP users only):\")\nprint(user_totals.collect())\n\n# DataFrame path\ndf = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"data/transactions.csv\")\ndf.groupBy(\"user_id\").agg(\n    F.sum(\"amount\").alias(\"total_amount\"),\n    F.avg(\"amount\").alias(\"avg_amount\")\n).orderBy(\"user_id\").show()\n\nspark.stop()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}