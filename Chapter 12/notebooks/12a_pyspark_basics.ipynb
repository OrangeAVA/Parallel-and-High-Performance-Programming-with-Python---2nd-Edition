{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"PySpark Basics\").master(\"local[*]\").getOrCreate()\n\ndata = [(\"Alice\", 29, \"Rome\"),\n        (\"Bob\", 35, \"Milan\"),\n        (\"Cathy\", 23, \"Naples\"),\n        (\"David\", 40, \"Venice\")]\ncolumns = [\"Name\", \"Age\", \"City\"]\ndf = spark.createDataFrame(data, schema=columns)\n\nprint(\"DataFrame schema:\")\ndf.printSchema()\nprint(\"\\nDataFrame content:\")\ndf.show()\n\nprint(\"\\nFilter Age > 30:\")\ndf.filter(df[\"Age\"] > 30).show()\n\nprint(\"\\nGroup by City, avg Age:\")\ndf.groupBy(\"City\").avg(\"Age\").show()\n\nprint(\"\\nOrder by Age desc:\")\ndf.orderBy(df[\"Age\"].desc()).show()\n\n# SQL\ndf.createOrReplaceTempView(\"citizens\")\nprint(\"\\nSQL: Age > 30\")\nspark.sql(\"SELECT Name, Age, City FROM citizens WHERE Age > 30\").show()\n\nprint(\"\\nSQL: AVG(Age) by City\")\nspark.sql(\"SELECT City, AVG(Age) AS AvgAge FROM citizens GROUP BY City\").show()\n\nprint(\"\\nSQL: ORDER BY Age DESC\")\nspark.sql(\"SELECT * FROM citizens ORDER BY Age DESC\").show()\n\nspark.stop()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}