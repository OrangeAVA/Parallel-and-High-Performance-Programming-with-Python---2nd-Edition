{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import explode, split, current_timestamp, window\n\nspark = SparkSession.builder.appName(\"Structured Streaming Parquet\").master(\"local[*]\").getOrCreate()\n\nlines = (spark.readStream\n    .format(\"socket\")\n    .option(\"host\",\"localhost\")\n    .option(\"port\", 9999)\n    .load())\n\nwith_ts = lines.withColumn(\"timestamp\", current_timestamp())\nwords = with_ts.select(explode(split(with_ts.value, \" \")).alias(\"word\"), \"timestamp\")\n\ncounts = (words\n    .withWatermark(\"timestamp\",\"10 seconds\")\n    .groupBy(window(\"timestamp\",\"1 minute\"), \"word\")\n    .count())\n\nquery = (counts.writeStream\n    .outputMode(\"append\")  # requires watermark\n    .format(\"parquet\")\n    .option(\"path\",\"output\")\n    .option(\"checkpointLocation\",\"checkpoints\")\n    .start())\n\nquery.awaitTermination(300)\nspark.stop()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}