{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nspark = SparkSession.builder.appName(\"MLlib Logistic Regression\").master(\"local[*]\").getOrCreate()\n\ndata = [\n    (25, 30000, 1, 0),\n    (35, 50000, 0, 1),\n    (45, 100000, 1, 1),\n    (22, 35000, 0, 0),\n    (44, 60000, 1, 1),\n    (33, 35000, 1, 1),\n    (50, 22000, 0, 0),\n    (30, 47000, 0, 1),\n    (48, 50000, 1, 1),\n]\ncolumns = [\"Age\", \"Salary\", \"Subscriber\", \"Purchased\"]\ndf = spark.createDataFrame(data, schema=columns)\n\nassembler = VectorAssembler(inputCols=[\"Age\",\"Salary\",\"Subscriber\"], outputCol=\"features\")\ndf2 = assembler.transform(df)\n\ntrain, test = df2.randomSplit([0.8, 0.2], seed=42)\n\nlr = LogisticRegression(featuresCol=\"features\", labelCol=\"Purchased\")\nmodel = lr.fit(train)\n\npred = model.transform(test)\npred.select(\"features\",\"Purchased\",\"prediction\",\"probability\").show(truncate=False)\n\nevaluator = BinaryClassificationEvaluator(labelCol=\"Purchased\", rawPredictionCol=\"rawPrediction\")\nauc = evaluator.evaluate(pred)\nprint(f\"AUC: {auc:.4f}\")\n\nspark.stop()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}