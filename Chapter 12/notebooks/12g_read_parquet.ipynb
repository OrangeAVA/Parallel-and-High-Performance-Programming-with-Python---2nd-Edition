{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"Read Parquet\").master(\"local[*]\").getOrCreate()\ndf = spark.read.parquet(\"output\")\ndf.show(truncate=False)\ndf.printSchema()\n\n# SQL-style aggregation\ndf.createOrReplaceTempView(\"words\")\nresult = spark.sql(\"SELECT word, SUM(count) as total FROM words GROUP BY word ORDER BY total DESC\")\nresult.show()\n\nspark.stop()\n\n# Optional: Pandas & Dask\ntry:\n    import pandas as pd\n    pdf = pd.read_parquet(\"output\")\n    print(\"\\nPandas head():\")\n    print(pdf.head())\nexcept Exception as e:\n    print(\"Pandas read_parquet skipped:\", e)\n\ntry:\n    import dask.dataframe as dd\n    ddf = dd.read_parquet(\"output\")\n    print(\"\\nDask head():\")\n    print(ddf.head())\nexcept Exception as e:\n    print(\"Dask read_parquet skipped:\", e)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}