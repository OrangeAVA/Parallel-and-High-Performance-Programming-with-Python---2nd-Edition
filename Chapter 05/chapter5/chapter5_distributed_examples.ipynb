{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9eddd4",
   "metadata": {},
   "source": [
    "# Chapter 5 — Distributed Python\n",
    "Examples for Celery, Dramatiq, and SCOOP.\n",
    "> Many cells require external services (Redis/RabbitMQ) and won't run in an offline notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5082e",
   "metadata": {},
   "source": [
    "## Celery — minimal app & tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from celery import Celery\n",
    "\n",
    "# Choose your broker/backend; here we default to Redis on localhost.\n",
    "# For RabbitMQ, set broker='pyamqp://guest@localhost//' and a suitable backend (e.g. 'rpc://', or Redis).\n",
    "app = Celery('tasks', broker='redis://localhost//', backend='redis://localhost')\n",
    "# Helpful for startup races with broker containers\n",
    "app.conf.broker_connection_retry_on_startup = True\n",
    "\n",
    "@app.task\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "@app.task\n",
    "def mul(x, y):\n",
    "    return x * y\n",
    "\n",
    "@app.task\n",
    "def xsum(numbers):\n",
    "    return sum(numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a7a26",
   "metadata": {},
   "source": [
    "### Client calls (requires running worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tasks import add\n",
    "# Basic fire-and-forget enqueue\n",
    "r1 = add.delay(4, 4)\n",
    "# Or via apply_async\n",
    "r2 = add.apply_async(args=[10, 5])\n",
    "\n",
    "print(\"Queued tasks. If you have a result backend configured, you can .get():\")\n",
    "try:\n",
    "    print(\"add(4,4) =\", r1.get(timeout=10))\n",
    "    print(\"add(10,5) =\", r2.get(timeout=10))\n",
    "except Exception as e:\n",
    "    print(\"Could not fetch results (did you configure a backend?):\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff69561",
   "metadata": {},
   "source": [
    "## Celery flows: group, chain, chord (Redis backend for chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from celery import group, chain, chord\n",
    "from tasks import add, mul, xsum\n",
    "\n",
    "# GROUP: run many independent tasks and collect all results\n",
    "g = group(add.s(i, i) for i in range(10))()\n",
    "print(\"GROUP results:\", g.get())\n",
    "\n",
    "# CHAIN: pipe result from one task into the next\n",
    "c = chain(add.s(4, 4) | mul.s(8))()\n",
    "print(\"CHAIN result:\", c.get())\n",
    "\n",
    "# CHORD: fan-out (group) + fan-in (callback)\n",
    "# Requires a backend that supports chords (Redis, Database, Memcached, ...).\n",
    "ch = chord((add.s(i, i) for i in range(10)), xsum.s())()\n",
    "print(\"CHORD result:\", ch.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdaedd",
   "metadata": {},
   "source": [
    "## Monte Carlo π with Celery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from celery import Celery, group, chord\n",
    "import random\n",
    "\n",
    "app = Celery('pi_calculator', broker='redis://localhost//', backend='redis://localhost')\n",
    "app.conf.broker_connection_retry_on_startup = True\n",
    "\n",
    "@app.task\n",
    "def simulate_points(n_points: int):\n",
    "    inside = 0\n",
    "    for _ in range(n_points):\n",
    "        x, y = random.random(), random.random()\n",
    "        if x*x + y*y <= 1.0:\n",
    "            inside += 1\n",
    "    return {'inside': inside, 'total': n_points}\n",
    "\n",
    "@app.task\n",
    "def calculate_pi(partials):\n",
    "    total_points = sum(d['total'] for d in partials)\n",
    "    inside = sum(d['inside'] for d in partials)\n",
    "    return 4.0 * inside / total_points\n",
    "\n",
    "@app.task\n",
    "def run_simulation(n_points_per_task: int, n_tasks: int):\n",
    "    sims = group(simulate_points.s(n_points_per_task) for _ in range(n_tasks))\n",
    "    return chord(sims, calculate_pi.s())()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pi_calculator import run_simulation, simulate_points, calculate_pi\n",
    "from celery import group\n",
    "\n",
    "# Two ways to run: 1) group + get + calculate locally; 2) single chord via run_simulation\n",
    "\n",
    "# 1) Group then reduce manually\n",
    "n_points_per_task = 200_000\n",
    "n_tasks = 10\n",
    "grp_res = group(simulate_points.s(n_points_per_task) for _ in range(n_tasks))()\n",
    "partials = grp_res.get()\n",
    "pi1 = calculate_pi(partials)\n",
    "print(\"Pi (manual reduce):\", pi1)\n",
    "\n",
    "# 2) Single chord\n",
    "chord_res = run_simulation.delay(n_points_per_task, n_tasks)\n",
    "print(\"Pi (chord):\", chord_res.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e8388",
   "metadata": {},
   "source": [
    "## Celery Queues and Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from celery import Celery\n",
    "from kombu import Queue, Exchange\n",
    "\n",
    "app = Celery('myapp', broker='redis://localhost//', backend='redis://localhost/')\n",
    "app.conf.broker_connection_retry_on_startup = True\n",
    "\n",
    "# Define queues and exchanges\n",
    "app.conf.task_queues = (\n",
    "    Queue('default', Exchange('default'), routing_key='default'),\n",
    "    Queue('high_priority', Exchange('priority'), routing_key='high.#'),\n",
    "    Queue('low_priority',  Exchange('priority'), routing_key='low.#'),\n",
    ")\n",
    "\n",
    "# Routing rules\n",
    "app.conf.task_routes = {\n",
    "    'tasks.send_email':      {'queue': 'high_priority'},\n",
    "    'tasks.process_data':    {'queue': 'low_priority'},\n",
    "    'tasks.backup_database': {'queue': 'default'},\n",
    "}\n",
    "\n",
    "# Misc\n",
    "app.conf.imports = ('tasks',)\n",
    "app.conf.task_default_queue = 'default'\n",
    "app.conf.task_default_exchange = 'default'\n",
    "app.conf.task_default_routing_key = 'default'\n",
    "app.conf.result_expires = 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b25370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from celery_app import app\n",
    "import time\n",
    "\n",
    "@app.task(queue='high_priority', priority=0)  # max priority\n",
    "def send_email(recipient, subject, body):\n",
    "    print(f\"Sent email to {recipient} with subject '{subject}'\")\n",
    "    time.sleep(2)\n",
    "    return f\"Email sent to {recipient}\"\n",
    "\n",
    "@app.task(queue='low_priority', priority=9)   # min priority\n",
    "def process_data(data):\n",
    "    print(f\"Start processing data: {data}\")\n",
    "    time.sleep(10)\n",
    "    return f\"Processed Data: {data}\"\n",
    "\n",
    "@app.task(queue='default')\n",
    "def backup_database():\n",
    "    print(\"Backup of database is running...\")\n",
    "    time.sleep(5)\n",
    "    return \"Backup completed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tasks import send_email, process_data, backup_database\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting tasks...\")\n",
    "    send_email.delay(\"user@example.com\", \"Welcome!\", \"Thanks for registration\")\n",
    "    send_email.delay(\"admin@example.com\", \"Alarm\", \"Critical problem found\")\n",
    "    process_data.delay(\"dataset_1\")\n",
    "    process_data.delay(\"dataset_2\")\n",
    "    backup_database.delay()\n",
    "    print(\"Tasks sent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a0b27",
   "metadata": {},
   "source": [
    "## Dramatiq — actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed024667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dramatiq\n",
    "import time\n",
    "\n",
    "# Tip: For Redis broker, you can configure via environment variables or explicit setup.\n",
    "# This minimal example relies on defaults when launched with `dramatiq dramaserver`.\n",
    "\n",
    "@dramatiq.actor\n",
    "def wait(t, n):\n",
    "    time.sleep(t)\n",
    "    print(f\"I am the actor {n} and I will wait for {t} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef64bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dramaserver import wait\n",
    "\n",
    "# Fire-and-forget multiple messages\n",
    "for i in range(10):\n",
    "    wait.send(i, f\"#{i}\")\n",
    "\n",
    "print(\"End Program\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbcbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dramatiq import group\n",
    "from dramaserver import wait\n",
    "\n",
    "g = group([\n",
    "    wait.message(10, 'A'),\n",
    "    wait.message(5,  'B'),\n",
    "    wait.message(4,  'C'),\n",
    "    wait.message(7,  'D'),\n",
    "]).run()\n",
    "\n",
    "print(\"End Program\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c91e0",
   "metadata": {},
   "source": [
    "### Dramatiq with results via Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999cae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import dramatiq\n",
    "from dramatiq.brokers.redis import RedisBroker\n",
    "from dramatiq.results import Results\n",
    "from dramatiq.results.backends import RedisBackend\n",
    "\n",
    "broker = RedisBroker(host=\"localhost\")\n",
    "dramatiq.set_broker(broker)\n",
    "result_backend = RedisBackend(host=\"localhost\")\n",
    "broker.add_middleware(Results(backend=result_backend))\n",
    "\n",
    "@dramatiq.actor(store_results=True)\n",
    "def wait(t, n):\n",
    "    time.sleep(t)\n",
    "    print(f\"I am the actor {n} and I will wait for {t} secs\")\n",
    "    return f\"I waited for {t} secs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dramatiq import group\n",
    "from dramaserver_results import wait\n",
    "from dramatiq.brokers.redis import RedisBroker\n",
    "from dramatiq.results import Results\n",
    "from dramatiq.results.backends import RedisBackend\n",
    "import dramatiq\n",
    "\n",
    "broker = RedisBroker(host=\"localhost\")\n",
    "dramatiq.set_broker(broker)\n",
    "result_backend = RedisBackend(host=\"localhost\")\n",
    "broker.add_middleware(Results(backend=result_backend))\n",
    "\n",
    "g = group([\n",
    "    wait.message(10, 'A'),\n",
    "    wait.message(5,  'B'),\n",
    "    wait.message(4,  'C'),\n",
    "    wait.message(7,  'D'),\n",
    "]).run()\n",
    "\n",
    "for res in g.get_results(block=True, timeout=12000):\n",
    "    print(res)\n",
    "\n",
    "print(\"End Program\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93bebf6",
   "metadata": {},
   "source": [
    "## SCOOP — basic mapping and reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scoop import futures\n",
    "\n",
    "def worker(value):\n",
    "    print(\"I am the Worker %s\" % value)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Synchronize with list() so the program waits for completion\n",
    "    list(futures.map(worker, range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scoop import futures\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def func(value):\n",
    "    result = math.sqrt(value)\n",
    "    print(\"The value %s and the elaboration is %s\" % (value, result))\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.array([10,3,6,1,4,8,25,9])\n",
    "    results = list(futures.map(func, data))\n",
    "    for result in results:\n",
    "        print(\"This is the result: %s\" % result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a15ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scoop import futures\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "def func(value):\n",
    "    result = math.sqrt(value)\n",
    "    print(\"The value %s and the elaboration is %s\" % (value, result))\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.array([10,3,6,1,4,8,25,9])\n",
    "    # Single reduce\n",
    "    total = sum(futures.map(func, data))\n",
    "    print(\"This is the reduction result:\", total)\n",
    "\n",
    "    # Using mapReduce\n",
    "    total2 = futures.mapReduce(func, operator.add, data)\n",
    "    print(\"This is the reduction result (mapReduce):\", total2)\n",
    "\n",
    "    # Chained mapping then reduction (mean of int(sqrt(x)))\n",
    "    import numpy as np\n",
    "    mean_val = np.mean(list(futures.map(int, futures.map(func, data))))\n",
    "    print(\"Mean of int(sqrt(x)):\", mean_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065141c",
   "metadata": {},
   "source": [
    "### Monte Carlo π with SCOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92274fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scoop import futures\n",
    "import random\n",
    "\n",
    "def simulate_points(n_points):\n",
    "    inside = 0\n",
    "    for _ in range(n_points):\n",
    "        x, y = random.random(), random.random()\n",
    "        if x*x + y*y <= 1:\n",
    "            inside += 1\n",
    "    return inside\n",
    "\n",
    "def main():\n",
    "    n_points_total = 10_000_00  # 1e6 (adjust up for more accuracy)\n",
    "    n_workers = 4\n",
    "    n_points_per_worker = n_points_total // n_workers\n",
    "    results = futures.map(simulate_points, [n_points_per_worker] * n_workers)\n",
    "    total_inside = sum(results)\n",
    "    pi_estimate = 4 * total_inside / n_points_total\n",
    "    print(f\"Estimate value of pi: {pi_estimate}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
